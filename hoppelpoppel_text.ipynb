{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the children's story \"Hoppelpoppel - wo bist du\" by my most favourite author from the last years, Hans Fallada\n",
    "# as a preparation for a visualization in Tableau.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bs4\n",
    "from urllib.request import urlopen as uReq\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from itertools import chain\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping story text\n",
    "\n",
    "my_url = 'https://www.projekt-gutenberg.org/fallada/hoppelpo/chap001.html'\n",
    "\n",
    "uClient = uReq(my_url)\n",
    "page_html = uClient.read()\n",
    "uClient.close()\n",
    "\n",
    "page_soup = soup(page_html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = page_soup.find_all('p')\n",
    "container = container[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = container.find_all('h3')\n",
    "title = str(title[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "story = container.find_all('p')\n",
    "paragraphs = []\n",
    "for i in story:\n",
    "    paragraphs.append(str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(paragraphs)):\n",
    "    paragraphs[i] = paragraphs[i].replace('<p>', '')\n",
    "    paragraphs[i] = paragraphs[i].replace('</p>', '') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "try:\n",
    "    for i in range(len(paragraphs)):\n",
    "        for j in range(len(paragraphs[i])):\n",
    "            words.append(paragraphs[j].split(' ')) \n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten nested lists in words\n",
    "\n",
    "words = list(chain.from_iterable(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(words)):\n",
    "        words[i] = words[i].strip()\n",
    "        words[i] = words[i].replace('\\xa0...', '')\n",
    "        words[i] = words[i].replace('<a', '')\n",
    "        words[i] = words[i].replace('</a>', '')\n",
    "        words[i] = words[i].replace('\\n', '')\n",
    "        words[i] = words[i].replace('-', '')\n",
    "        words[i] = words[i].replace('–', '')\n",
    "        words[i] = words[i].replace('.', '')\n",
    "        words[i] = words[i].replace(':', '')\n",
    "        words[i] = words[i].replace(',', '')\n",
    "        words[i] = words[i].replace('>', '')\n",
    "        words[i] = words[i].replace('<', '')\n",
    "        words[i] = words[i].replace('›', '')\n",
    "        words[i] = words[i].replace('‹', '')\n",
    "        words[i] = words[i].replace('?', '')\n",
    "        words[i] = words[i].replace('!', '')\n",
    "        words[i] = words[i].replace('«', '')\n",
    "        words[i] = words[i].replace('»', '')\n",
    "        words[i] = words[i].replace('(', '')\n",
    "        words[i] = words[i].replace(')', '')\n",
    "        words[i] = words[i].replace(' ', '')\n",
    "        words[i] = re.sub(str('id='+'\"'+'page\\d'+'\"'), '', words[i])\n",
    "        words[i] = re.sub(str('name='+'\"'+'page\\d'+'\"'), '', words[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove empty strings in words\n",
    "\n",
    "while(\"\" in words) :\n",
    "    words.remove(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.columns = ['rank', 'text']\n",
    "df.columns = ['rank', 'text']\n",
    "df['text2'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning last HTML code\n",
    "\n",
    "part1 = df[df.text == 'title=\"Dieter7/lac\"']\n",
    "part2 = df[df.text == 'title=\"suru/Dieter7\"']\n",
    "part3 = df[df.text == 'title=\"lac/Dieter7\"']\n",
    "eraser = pd.concat([part1, part2, part3])\n",
    "\n",
    "erank = []\n",
    "for i in range(len(eraser)):\n",
    "    erank.append(int(eraser.index[i]))\n",
    "\n",
    "for i in erank:\n",
    "    df = df.drop([i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('rank', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['rank', 'text', 'text2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-19-d31fb755fdcd>:6: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df['text2'][i] = df.text[i+1]\n"
     ]
    }
   ],
   "source": [
    "# Fill 'text2' with text from previous row\n",
    "\n",
    "for i in range(len(df)-1):\n",
    "    if i < len(df):\n",
    "        try:\n",
    "            df['text2'][i] = df.text[i+1] \n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text3_lowercase'] = df.text.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting for displaying the full dataframe \n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe with German words in lowercase for count of unique values\n",
    "\n",
    "df2 = pd.Series(df.text3_lowercase.unique())\n",
    "df2 = pd.DataFrame(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.columns = ['text_unique']\n",
    "df2['count_text'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the unique words\n",
    "\n",
    "for i in range(len(df2)):\n",
    "    x = df2.text_unique[i]      # x stores each single word in text_unique\n",
    "    df2['count_text'][i] = df[df.text3_lowercase == x].text3_lowercase.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['count_text'] = ''\n",
    "df['lat'] = ''\n",
    "df['lon'] = ''\n",
    "df['path_ID'] = ''\n",
    "df['path_start_end'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-26-07debcdcef62>:5: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df['count_text'][j] = df2.count_text[i]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df2)):\n",
    "    x = df2.text_unique[i]\n",
    "    for j in range(len(df)):\n",
    "        if df.text3_lowercase[j] == x:\n",
    "            df['count_text'][j] = df2.count_text[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(486, 2)"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('fallada_hoppelpoppel.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}